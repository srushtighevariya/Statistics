{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7dbdc5a",
   "metadata": {},
   "source": [
    "## Probability "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913c33f1",
   "metadata": {},
   "source": [
    "## Q-1\n",
    "\n",
    "1. Dice role 1000 times using numpy.random.randint()\n",
    "- calculate probability of each outcome using frequency distribution\n",
    "\n",
    "2. Coin toss 500 times.\n",
    "- Estimate probability of getting head ans tails\n",
    "\n",
    "3. Use collection.count() or value_counts() to get experimental probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a07b2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of each face in 1000 dice rolls:\n",
      " {np.int32(6): 0.159, np.int32(2): 0.157, np.int32(5): 0.17, np.int32(4): 0.193, np.int32(1): 0.159, np.int32(3): 0.162}\n",
      "\n",
      "Probability of heads and tails in 500 coin flips:\n",
      " {np.str_('T'): 0.46, np.str_('H'): 0.54}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Dice\n",
    "dice = np.random.randint(1,7, 1000)\n",
    "counts = Counter(dice)\n",
    "p_of_dice = {no:times/1000 for no,times in counts.items()}\n",
    "print(\"Probability of each face in 1000 dice rolls:\\n\", p_of_dice)\n",
    "\n",
    "# Coin\n",
    "coin = np.random.choice(['H','T'], 500)\n",
    "counts = Counter(coin)\n",
    "p_of_coin = {side:times/500 for side,times in counts.items()}\n",
    "print(\"\\nProbability of heads and tails in 500 coin flips:\\n\", p_of_coin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673e6051",
   "metadata": {},
   "source": [
    "## Q-2\n",
    "\n",
    "1. Simulates two set of data with different mean\n",
    "2. Perform a t-test using scipy.stats.ttest_ind() to get the p_value\n",
    "3. P_value Interpretation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -1.0385192635098568\n",
      "p-value: 0.30029492556610876\n",
      "**Interpretation:** p-value is greater than 0.05, so we fail to reject the null hypothesis.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Simulate two datasets with slightly different means\n",
    "data1 = np.random.normal(loc=50, scale=10, size=100)\n",
    "data2 = np.random.normal(loc=52, scale=10, size=100)\n",
    "\n",
    "# Perform independent t-test\n",
    "t_stat, p_value = stats.ttest_ind(data1, data2)\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Markdown-style interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"**Interpretation:** p-value is less than 0.05, so we reject the null hypothesis.\")\n",
    "else:\n",
    "    print(\"**Interpretation:** p-value is greater than 0.05, so we fail to reject the null hypothesis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9987e78e",
   "metadata": {},
   "source": [
    "## Q-3\n",
    "\n",
    "1. create a sample dataset with scores before and after training program\n",
    "2. Use paired t_test on a independent t-test for cheking improvement\n",
    "3. Calculate confidence interval using mean using scipy.stats.sem() and stats.t.interval()\n",
    "4. Set a significant level (alpha = 0.05) and determine if the null hypothesis should be determine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1434323b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired t-test p-value: 4.919703888938251e-06\n",
      "Confidence interval for mean difference: (np.float64(3.303106763447601), np.float64(7.113794711309729))\n",
      "**Conclusion:** Reject the null hypothesis. Training likely had a significant effect.\n"
     ]
    }
   ],
   "source": [
    "# from scipy import stats\n",
    "# import numpy as np\n",
    "\n",
    "# Simulate scores before and after training\n",
    "before = np.random.normal(loc=60, scale=8, size=30)\n",
    "after = before + np.random.normal(loc=5, scale=5, size=30)  # improvement\n",
    "\n",
    "# Paired t-test\n",
    "t_stat, p_value = stats.ttest_rel(before, after)\n",
    "print(\"Paired t-test p-value:\", p_value)\n",
    "\n",
    "# Confidence interval for mean difference\n",
    "mean_diff = np.mean(after - before)\n",
    "sem_diff = stats.sem(after - before)\n",
    "confidence_interval = stats.t.interval(0.95, len(before)-1, loc=mean_diff, scale=sem_diff)\n",
    "print(\"Confidence interval for mean difference:\", confidence_interval)\n",
    "\n",
    "# Decision based on Î± = 0.05\n",
    "if p_value < 0.05:\n",
    "    print(\"**Conclusion:** Reject the null hypothesis. Training likely had a significant effect.\")\n",
    "else:\n",
    "    print(\"**Conclusion:** Fail to reject the null hypothesis. No significant improvement detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c60651c",
   "metadata": {},
   "source": [
    "## Q-4\n",
    "\n",
    "1. Type 1 Error (False Positive):\n",
    "    - Rejecting the null hypothesis when it is actually true.  \n",
    "    - Example: Concluding a drug works when it actually doesn't.\n",
    "2. Type 2 Error (False Negative):\n",
    "    - Failing to reject the null hypothesis when it is actually false.  \n",
    "    - Example: Concluding a drug doesn't work when it actually does.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
